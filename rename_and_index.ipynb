{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "base_dir = \"RAG-Challenge-\\archive\"\n",
    "output_dir = \"/renamed_reports\"\n",
    "json_file_path = \"/data/meta.json\" \n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    with open(json_file_path, 'r', encoding='utf-8') as f:\n",
    "        company_data = json.load(f)\n",
    "    print(f\"JSON данные успешно загружены из {json_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Ошибка при загрузке JSON файла: {str(e)}\")\n",
    "    exit(1)\n",
    "\n",
    "def sanitize_filename(filename):\n",
    "    return re.sub(r'[\\\\/*?:\"<>|]', '_', filename)\n",
    "\n",
    "sha1_to_company = {item[\"sha1\"]: item[\"company_name\"] for item in company_data}\n",
    "\n",
    "processed = 0\n",
    "skipped = 0\n",
    "errors = 0\n",
    "\n",
    "print(f\"Начинаем обработку папок в {base_dir}...\")\n",
    "for sha1 in os.listdir(base_dir):\n",
    "    folder_path = os.path.join(base_dir, sha1)\n",
    "    if not os.path.isdir(folder_path):\n",
    "        continue\n",
    "    \n",
    "    if sha1 not in sha1_to_company:\n",
    "        print(f\"Предупреждение: Не найдено название компании для SHA1 {sha1}, пропускаем...\")\n",
    "        skipped += 1\n",
    "        continue\n",
    "    \n",
    "    company_name = sha1_to_company[sha1]\n",
    "    safe_company_name = sanitize_filename(company_name)\n",
    "    \n",
    "    md_file = os.path.join(folder_path, f\"{sha1}.md\")\n",
    "    \n",
    "    if not os.path.exists(md_file):\n",
    "        print(f\"Предупреждение: Не найден markdown файл для SHA1 {sha1}, пропускаем...\")\n",
    "        skipped += 1\n",
    "        continue\n",
    "    \n",
    "    new_file = os.path.join(output_dir, f\"{safe_company_name}.md\")\n",
    "    \n",
    "    try:\n",
    "        shutil.copy2(md_file, new_file)\n",
    "        print(f\"Успешно скопирован: {sha1}.md -> {safe_company_name}.md\")\n",
    "        processed += 1\n",
    "    except Exception as e:\n",
    "        print(f\"Ошибка копирования {sha1}.md: {str(e)}\")\n",
    "        errors += 1\n",
    "\n",
    "\n",
    "print(f\"- Успешно обработано файлов: {processed}\")\n",
    "print(f\"- Пропущено файлов: {skipped}\")\n",
    "print(f\"- Встречено ошибок: {errors}\")\n",
    "print(f\"Переименованные файлы находятся в: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "from opensearchpy import OpenSearch\n",
    "\n",
    "OPENSEARCH_CONFIG = {\n",
    "    \"hosts\": [{\"host\": \"\", \"port\": }],\n",
    "    \"http_auth\": (\"\", \"\"),\n",
    "    \"use_ssl\": True,\n",
    "    \"verify_certs\": True,\n",
    "    \"ssl_show_warn\": False,\n",
    "    \"timeout\": 120,\n",
    "    \"retry_on_timeout\": True,\n",
    "    \"max_retries\": 3\n",
    "}\n",
    "\n",
    "client = OpenSearch(**OPENSEARCH_CONFIG)\n",
    "\n",
    "INDEX_NAME = \"annual_reports\"\n",
    "\n",
    "if not client.indices.exists(index=INDEX_NAME):\n",
    "    index_body = {\n",
    "        \"settings\": {\n",
    "            \"analysis\": {\n",
    "                \"analyzer\": {\n",
    "                    \"rebuilt_english\": {\n",
    "                        \"tokenizer\": \"standard\",\n",
    "                        \"filter\": [\n",
    "                            \"lowercase\",\n",
    "                            \"english_stop\",\n",
    "                            \"english_stemmer\"\n",
    "                        ]\n",
    "                    }\n",
    "                },\n",
    "                \"filter\": {\n",
    "                    \"english_stop\": {\n",
    "                        \"type\": \"stop\",\n",
    "                        \"stopwords\": \"_english_\"\n",
    "                    },\n",
    "                    \"english_stemmer\": {\n",
    "                        \"type\": \"stemmer\",\n",
    "                        \"language\": \"english\"\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"company\": {\"type\": \"keyword\"},\n",
    "                \"page_number\": {\"type\": \"integer\"},\n",
    "                \"text\": {\"type\": \"text\", \"analyzer\": \"rebuilt_english\"}\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    client.indices.create(index=INDEX_NAME, body=index_body)\n",
    "    print(f\"Индекс {INDEX_NAME} создан.\")\n",
    "else:\n",
    "    print(f\"Индекс {INDEX_NAME} уже существует.\")\n",
    "\n",
    "MARKDOWN_FOLDER = \"/renamed_reports\"\n",
    "\n",
    "page_marker_pattern = re.compile(r\"^\\{(\\d+)\\}-+\\s*$\", re.MULTILINE)\n",
    "\n",
    "for file in os.listdir(MARKDOWN_FOLDER):\n",
    "    if file.endswith(\".md\"):\n",
    "        company_name = os.path.splitext(file)[0]\n",
    "        file_path = os.path.join(MARKDOWN_FOLDER, file)\n",
    "        with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "        \n",
    "        parts = re.split(page_marker_pattern, content)\n",
    "        \n",
    "        if parts and parts[0].strip() == \"\":\n",
    "            parts = parts[1:]\n",
    "        \n",
    "        for i in range(0, len(parts), 2):\n",
    "            try:\n",
    "                page_num = int(parts[i])\n",
    "            except ValueError:\n",
    "                continue\n",
    "            page_text = parts[i+1].strip() if (i+1) < len(parts) else \"\"\n",
    "            doc = {\n",
    "                \"company\": company_name,\n",
    "                \"page_number\": page_num,\n",
    "                \"text\": page_text\n",
    "            }\n",
    "            client.index(index=INDEX_NAME, body=doc)\n",
    "        print(f\"Проиндексирован файл: {file}\")\n",
    "\n",
    "def search_relevant_page(query, result_size=5):\n",
    "    search_body = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"text\": {\n",
    "                    \"query\": query,\n",
    "                    \"analyzer\": \"rebuilt_english\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        \"size\": result_size\n",
    "    }\n",
    "    response = client.search(index=INDEX_NAME, body=search_body)\n",
    "    return response\n",
    "\n",
    "user_query = input(\"Введите поисковый запрос: \")\n",
    "search_results = search_relevant_page(user_query)\n",
    "print(\"\\nРезультаты поиска:\")\n",
    "for hit in search_results[\"hits\"][\"hits\"]:\n",
    "    source = hit[\"_source\"]\n",
    "    print(f\"Score: {hit['_score']} | Company: {source['company']} | Page: {source['page_number']}\")\n",
    "    print(source[\"text\"])\n",
    "    print(\"-\" * 80)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
